
/::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** @author  John Miller, Hao Peng, Zhe Jin
 *  @version 2.0
 *  @date    Mon Jul 27 01:27:00 EDT 2015
 *  @see     LICENSE (MIT style license file).
 *
 *  @title   Model: Integer-Based Tree Augmented Naive Bayes (TAN) Classifier
 */

package scalation
package modeling
package classifying

import scala.collection.mutable.{Set => SET, Map}
import scala.runtime.ScalaRunTime.stringOf

import scalation.columnar_db.Relation
import scalation.graph_db.{MGraph, MinSpanningTree, Pair}
import scalation.mathstat._

//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayes` class implements an Integer-Based Tree Augmented Naive Bayes
 *  Classifier,  which is a commonly used such classifier for discrete input data.
 *  The classifier is trained using a data matrix x and a classification vector y.
 *  Each data vector in the matrix is classified into one of k classes numbered
 *  0, ..., k-1.  Prior probabilities are calculated based on the population of
 *  each class in the training-set.  Relative posterior probabilities are computed
 *  by multiplying these by values computed using conditional probabilities.
 *-----------------------------------------------------------------------------
 *  This classifier supports limited dependency between features/variables.
 *  @param x       the input/data m-by-n matrix
 *  @param y       the class vector, where y(i) = class for row i of matrix x
 *  @param fname_  the names of the features/variables
 *  @param k       the number of classes
 *  @param cname_  the names of the classes
 *  @param vc      the value count (number of distinct values) for each feature
 *  @param hparam  the hyper-parameters
 */
class TANBayes (x: MatrixD, y: VectorI, fname_ : Array [String] = null,
                k: Int = 2, cname_ : Array [String] = Array ("No", "Yes"),
                protected var vc: VectorI = null, hparam: HyperParameter = NaiveBayes.hp)
      extends Classifier (x, y, fname_, k, cname_, hparam)
         with FitC (y, k):

    private val debug = debugf ("TANBayes", true)                        // debug function
    private val flaw  = flawf ("TANBayes")                               // flaw function

    if cname.length != k then flaw ("init", "# class names != # classes")

    private val me     = hparam("me").toDouble                           // m-estimates (me == 0 => regular MLE estimates)
    private val me_vc  = VectorD (vc.map (me / _))                       // me / vc_j for all j
    private val (m, n) = (x.dim, x.dim2)                                 // number of (instances, variables)
    private val md     = m.toDouble                                      // m as a double (real number)

    private var parent = new VectorI (n)                                 // vector holding the parent for each feature/variable
    private val vcp    = new VectorI (n)                                 // value count for the parent

    protected val nu_XyP = new HMatrix4 [Int] (k, n)         // conditional frequency counts for variable/feature j: xj
    protected val p_XyP  = new HMatrix4 [Double] (k, n)      // conditional probabilities for variable/feature j: xj

    if vc == null then
        shiftToZero (); vc = vc_fromData                     // set value counts from data
    end if

    nu_X   = HMatrix2 [Int] (n, vc)                          // local frequency of X = [x_0, ... x_n-1]
    nu_Xy  = HMatrix3 [Int] (k, n, vc)                       // local joint frequency of X and y

    private val nu_X   = Array.ofDim [VectorI] (n)           // frequency of X = [x_0, ... x_n-1]
    private val nu_Xy  = Array.ofDim [MatrixI] (n)           // Joint Frequency Tables (JFTs) one per feature

    nu_XyZ = HMatrix5 [Int] (k, n, n, vc, vc)                // local joint frequency (using partial dataset, i.e. when using cross validation)
                                                             // of X, y and Z where X, Z are features/columns
    debug ("init", s" value count vc = $vc \n vcp = $vcp \n parent = $parent")

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Train the classifier by computing the probabilities for c, and the
     *  conditional probabilities for x_j.
     *  @param itest  indices of the instances considered as testing data - FIX
     */
    def train (itest: VectorI): Unit =
        val idx = VectorI.range (0, m) diff itest
        computeParent (idx)                                  // frequency computations are also done here
        computeVcp ()
        nu_XyP.alloc (vc, vcp)
        p_XyP.alloc (vc, vcp)
        copyFreqXyP ()
        train2 ()
    end train

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Train the classifier by computing the probabilities for y, and the
     *  conditional probabilities for x_j.
     */
    private def train2 (): Unit =
        p_y = nu_y.toDouble / md                             // probability for class yi
        for i <- 0 until k; j <- 0 until n do                // for each class yi & feature xj
            val me_vc = me / vc(j).toDouble
            for xj <- 0 until vc(j); xp <- 0 until vcp(j) do
                val d = if parent(j) > -1 then
                            nu_Xy(i, parent(j), xp)
                        else
                            nu_y(i)
                // for each value for feature j: xj, par(j): xp
                p_XyP(i, j, xj, xp) = (nu_XyP(i, j, xj, xp) + me_vc) / (d + me)
        end for

        debug ("train2", s" py   = $p_y \n p_XyP = $p_XyP")
    end train2

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Compute the parent of each feature based on the correlation matrix.
     *  Feature x_i is only a possible candidate for parent of feature x_j if *  i < j
     *  @param idx   indicies of either training or testing region
     */
    def computeParent (idx: VectorI): Unit =
        val cmiMx = calcCMI (idx, vc)
        for j1 <- 0 until n; j2 <- 0 until j1 do cmiMx(j1, j2) = cmiMx(j2, j1)

        val ch     = Array.fill (n)(SET [Int] ())
        val elabel = Map [Pair, Double] ()

        for i <- 0 until n; j <- i + 1 until n do { ch(i) += j; elabel += new Pair(i, j) -> cmiMx(i, j) }

        parent = { val a = maxSpanningTree (ch, elabel).makeITree (); new VectorI (a.size, a) }
    end computeParent

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Return the parent.
     */
    override def getParent: VectoI = parent

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Clone/copy the values from global freq variables into local ones.
     *  Only the joint frequencies of Class, X-feature, and its Parent needs
     *  to be copied for parameter learning purposes.
     */
    private def copyFreqXyP (): Unit =
        for i <- 0 until k; j <- x.indices2; xj <- 0 until vc(j); xp <- 0 until vcp(j) do
            nu_XyP(i, j, xj, xp) = if parent(j) > -1 then
                                       nu_XyZ(i, j, parent(j), xj, xp)
                                   else 
                                       nu_Xy(i, j, xj)
        end for
    end copyFreqXyP

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Increment frequency counters used in CMI calculations based on the 'i'th
     *  row of the data matrix.
     *  @param i  the index for current data row
     */
    protected def updateFreq (i: Int): Unit =
        val yi    = y(i)                                     // get the class for ith row
        nu_y(yi) += 1                                        // increment frequency for class yi
        for j <- x.indices2 do                               // for each feature/variable xj
            nu_X(j, x(i, j))      += 1                       // increment frequency for xj 
            nu_Xy(yi, j, x(i, j)) += 1                       // increment frequency for xj, yi
            for j2 <- j+1 until n do                         // for each feature/variable xj2
                nu_XyZ(yi, j, j2, x(i, j), x(i, j2)) += 1    // increment frequency for xj, yi, xj2
                nu_XyZ(yi, j2, j, x(i, j2), x(i, j)) += 1    // increment frequency for xj2, yi, xj
            end for
        end for
    end updateFreq

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Create MaxSpanningTree from conditional mutual information.
     *  @param ch      the adjacency set
     *  @param elabel  the edge labels/weights
     */
    def maxSpanningTree (ch: Array [SET [Int]], elabel: Map [Pair, Double]): MinSpanningTree =
        val g = new MGraph (ch, Array.ofDim (n), elabel)
        new MinSpanningTree (g, false, false)                // param 2 = false means max spanning tree
    end maxSpanningTree

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Compute the value counts of each parent feature based on the parent vector.
     *  Let 1 be the default value count when there is no parent.
     */
    def computeVcp (): Unit =
        for j <- vcp.indices do
            vcp(j) = if parent(j) > -1 then vc(parent(j)) else 1
        end for
    end computeVcp

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Given a discrete data vector 'z', classify it returning the class number
     *  (0, ..., k-1) with the highest relative posterior probability.
     *  Return the best class, its name and its relative probability.
     *  @param z  the data vector to classify
     */
    def predictI (z: VectoI): Int =
        val prob = new VectorD (p_y)
        for i <- 0 until k; j <- 0 until n do
            prob(i) *= (if parent(j) > -1 then
                            p_XyP(i, j, z(j), z(parent(j)))   // P(X_j = z_j | X_p = z_p, y = c), x-parent
                        else
                            p_XyP(i, j, z(j), 0))             // P(X_j = z_j | x_p = z_p, y = c), no x-parent
        end for
        prob.argmax ()                            // class with the highest relative posterior probability
    end predictI

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Reset or re-initialize the frequency tables.
     */
    def reset (): Unit =
        nu_y.set (0)
        nu_X.set (0)
        nu_Xy.set (0)
        nu_XyZ.set (0)
    end reset

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Print the conditional probability tables by iterating over the features/variables.
     */
    def printConditionalProb (): Unit =
        for j <- p_XyP.indices2 do
            println (s"ConditionalProb for x$j = ${p_XyP(j)}")
        end for
    end printConditionalProb

end TANBayes


//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayes` object is the companion object for the `TANBayes` class.
 */
object TANBayes

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Create a `TANBayes` object, passing x and y together in one matrix.
     *  @param xy      the combined data-response matrix
     *  @param fname   the names of the features/variables
     *  @param k       the number of classes
     *  @param cname   the names of the classes
     *  @param vc      the value count (number of distinct values) for each feature
     *  @param hparam  the hyper-parameters
     */
    def apply (xy: MatrixI, fname: Array [String] = null, k: Int = 2,
               cname: Array [String] = Array ("No", "Yes"), vc: VectorI = null,
               hparam: HyperParameter = NaiveBayes.hp)
              (col: Int = xy.dim2 - 1): TANBayes =
        val (x, y) = (xy.not(?, col), xy(?, col).toInt)              // data matrix, response vector
        new TANBayes (x, y, fname, k, cname, vc, hparam)
    end apply

end TANBayes


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayesTest` object is used to test the `TANBayes0` and 'TANBayes' classes.
 *  > runMain scalation.analytics.classifier.TANBayesTest
 */
object TANBayesTest extends App
{
    import ExampleTennis._

    banner ("Tennis Example")
    println ("xy = " + xy)
    println ("-" * 60)
    val x = xy.sliceCol (0, xy.dim2 - 1)                        // data/input matrix
    val y = xy.col (xy.dim2 - 1)                                // response/class label vector
    println (s"x = $x")

    val tan0 = TANBayes0 (xy, fn, k, cn)                        // create a classifier tan0
    tan0.train ()                                               // train the classifier tan0
    val tan  = TANBayes  (xy, fn, k, cn)                        // create a classifier tan
    ClassifierInt.analyze (tan)

    tan.printClassProb ()                                       // print class probabilities
    tan.printConditionalProb ()                                 // print conditional probabilities

    val z = VectorI (2, 2, 1, 1)                                // new data vector to classify
    banner (s"Classify $z")
    println (s"Use tan0 to classify ($z) = " + tan0.classify (z))
    println (s"Use tan  to classify ($z) = " + tan.classify (z))

    banner ("All Test")
    val yp = tan.classify ()
    tan.contrast (yp)
    println (tan.report)
    println (tan.summary (tan.parameter))

    banner ("Cross-validation for TANBayes0")
    tan0.crossValidateRand (10, true)
    banner ("Cross-validation for TANBayes")
    tan.crossValidateRand (10, true)

} // TANBayesTest object


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayesTest2` object is used to test the `TANBayes0` and `TANBayes` classes.
 *  Classify whether a car is more likely to be stolen (1) or not (1).
 *  @see www.inf.u-szeged.hu/~ormandi/ai2/06-AugNaiveBayes-example.pdf
 *  > runMain scalation.analytics.classifier.TANBayesTest2
 */
object TANBayesTest2 extends App
{
    // x0: Color:   Red (1), Yellow (0)
    // x1: Type:    SUV (1), Sports (0)
    // x2: Origin:  Domestic (1), Imported (0)
    // features:                x0 x1 x2
    val x = new MatrixI((10, 3), 1, 0, 1,                       // data matrix
                                 1, 0, 1,
                                 1, 0, 1,
                                 0, 0, 1,
                                 0, 0, 0,
                                 0, 1, 0,
                                 0, 1, 0,
                                 0, 1, 1,
                                 1, 1, 0,
                                 1, 0, 0)

    val y  = VectorI (1, 0, 1, 0, 1, 0, 1, 0, 0, 1)             // classification vector: 0(No), 1(Yes))
    val fn = Array ("Color", "Type", "Origin")                  // feature/variable names
    val cn = Array ("No", "Yes")                                // class names

    println ("xy = " + (x :^+ y))
    println ("-" * 60)

    val tan0 = new TANBayes0 (x, y, fn, 2, cn)                  // create the classifier
    tan0.train ()
    val tan  = new TANBayes  (x, y, fn, 2, cn)                  // create the classifier
    ClassifierInt.analyze (tan)

    // test sample ------------------------------------------------------------
    val z1 = VectorI (1, 0, 1)                                  // existing data vector to classify
    val z2 = VectorI (1, 1, 1)                                  // new data vector to classify
    println (s"Use tan0 to classify ($z1) = " + tan0.classify (z1))
    println (s"Use tan  to classify ($z1) = " + tan.classify (z1))
    println (s"Use tan0 to classify ($z2) = " + tan0.classify (z2))
    println (s"Use tan  to classify ($z2) = " + tan.classify (z2))

    banner ("All Test")
    val yp = tan.classify ()
    tan.contrast (yp)
    println (tan.report)
    println (tan.summary (tan.parameter))

    banner ("Cross-validation for TANBayes0")
    tan0.crossValidateRand ()
    banner ("Cross-validation for TANBayes")
    tan.crossValidateRand ()

} // TANBayesTest2 object


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayesTest3` object is used to test the `TANBayes0` and `TANBayes` classes.
 *  Given whether a person is Fast and/or Strong, classify them as making C = 1
 *  or not making C = 0 the football team.
 *  > runMain scalation.analytics.classifier.TANBayesTest3
 */
object TANBayesTest3 extends App
{
    // training-set -----------------------------------------------------------
    // x0: Fast
    // x1: Strong
    // y:  Classification (No/0, Yes/1)
    // features:                 x0 x1  y
    val xy = new MatrixI((10, 3), 1, 1, 1,
                                  1, 1, 1,
                                  1, 0, 1,
                                  1, 0, 1,
                                  1, 0, 0,
                                  0, 1, 0,
                                  0, 1, 0,
                                  0, 1, 1,
                                  0, 0, 0,
                                  0, 0, 0)

    val fn = Array ("Fast", "Strong")                           // feature names
    val cn = Array ("No", "Yes")                                // class names

    println("xy = " + xy)
    println ("-" * 60)

    val tan0 = TANBayes0 (xy, fn, 2, cn, 1, null)               // create the classifier
    tan0.train ()
    val tan  = TANBayes  (xy, fn, 2, cn, 1, null)               // create the classifier
    ClassifierInt.analyze (tan)

    // test sample ------------------------------------------------------------
    val z = VectorI (1, 0) // new data vector to classify
    println (s"Use tan0 to classify ($z) = " + tan0.classify (z))
    println (s"Use tan  to classify ($z) = " + tan.classify (z))

    banner ("All Test")
    val yp = tan.classify ()
    tan.contrast (yp)
    println (tan.report)
    println (tan.summary (tan.parameter))

    banner ("Cross-validation for TANBayes0")
    tan0.crossValidateRand ()
    banner ("Cross-validation for TANBayes")
    tan.crossValidateRand ()

} // TANBayesTest3 object


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `TANBayesTest4` object is used to test the `TANBayes0` and `TANBayes` classes.
 *  > runMain scalation.analytics.classifier.TANBayesTest4
 */
object TANBayesTest4 extends App
{
    val filename = BASE_DIR + "breast-cancer.arff"
    var data = Relation (filename, -1, null)
    val xy = data.toMatriI2 (null)
    val fn = data.colName.slice (0, xy.dim2 - 1).toArray
    val cn = Array ("p", "e")                                   // class names
    val k  = 2
    println ("-" * 60)

    val tan0 = TANBayes0 (xy, fn, k, cn)                        // create the classifier
    tan0.train ()
    val tan  = TANBayes  (xy, fn, k, cn)                        // create the classifier
    ClassifierInt.analyze (tan)

    banner ("All Test")
    val yp = tan.classify ()
    tan.contrast (yp)
    println (tan.report)
    println (tan.summary (tan.parameter))

    tan0.featureSelection ()
    tan.featureSelection ()

    banner ("Cross-validation for TANBayes0")
    tan0.crossValidateRand ()
    banner ("Cross-validation for TANBayes")
    tan.crossValidateRand ()

    println ("After feature selection")

    banner ("Cross-validation for TANBayes0")
    tan0.crossValidateRand ()
    banner ("Cross-validation for TANBayes")
    tan.crossValidateRand ()

} // TANBayesTest4 object

